{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pdf2image pytesseract pdfplumber langchain-community transformers torch faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882633be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import logging, re\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pdfplumber\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pdf2image\").setLevel(logging.ERROR)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE, DEV_ID = \"cuda\", 0\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    DEVICE, DEV_ID = \"mps\", 0\n",
    "else:\n",
    "    DEVICE, DEV_ID = \"cpu\", -1\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34dd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_ocr(pdf_path: Path, lang: str = \"hin\") -> str:\n",
    "    pages = convert_from_path(str(pdf_path), dpi=300)\n",
    "    texts = []\n",
    "    for i, img in enumerate(pages, 1):\n",
    "        txt = pytesseract.image_to_string(img, lang=lang)\n",
    "        texts.append(txt)\n",
    "    return \"\\n\".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd512496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data\")\n",
    "ocr_dir  = Path(\"ocr_texts\")\n",
    "ocr_dir.mkdir(exist_ok=True)\n",
    "\n",
    "pdf_hi = data_dir/\"Constitution_Hindi.pdf\"\n",
    "txt_hi = ocr_dir/\"Constitution_Hindi.txt\"\n",
    "if pdf_hi.exists() and not txt_hi.exists():\n",
    "    text = extract_text_ocr(pdf_hi, lang=\"hin\")\n",
    "    txt_hi.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "pdf_ipc = data_dir/\"IPC_hindi.pdf\"\n",
    "txt_ipc = ocr_dir/\"IPC_hindi.txt\"\n",
    "if pdf_ipc.exists() and not txt_ipc.exists():\n",
    "    text = extract_text_ocr(pdf_ipc, lang=\"hin\")\n",
    "    txt_ipc.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "for name in [\"Constitution_Hindi.txt\",\"IPC_hindi.txt\"]:\n",
    "    src = data_dir/name\n",
    "    dst = ocr_dir/name\n",
    "    if src.exists() and not dst.exists():\n",
    "        dst.write_text(src.read_text(\"utf-8\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ec4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "constitution_hindi = (ocr_dir/\"Constitution_Hindi.txt\").read_text(encoding=\"utf-8\")\n",
    "ipc_hindi          = (ocr_dir/\"IPC_hindi.txt\").read_text(encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230cd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hindi source docs: 2\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(page_content=constitution_hindi, metadata={\"source\":\"Constitution_Hindi.txt\"}),\n",
    "    Document(page_content=ipc_hindi,        metadata={\"source\":\"IPC_hindi.txt\"}),\n",
    "]\n",
    "print(\"Total Hindi source docs:\", len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb74fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hindi chunks: 926\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "    text = re.sub(r'[^\\S\\n]+',' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "hindi_chunks = []\n",
    "for doc in docs:\n",
    "    cleaned = clean_text(doc.page_content)\n",
    "    for i, chunk in enumerate(splitter.split_text(cleaned)):\n",
    "        m = dict(doc.metadata); m[\"chunk\"]=i\n",
    "        hindi_chunks.append(Document(page_content=chunk, metadata=m))\n",
    "print(\"Total Hindi chunks:\", len(hindi_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5b61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/rxbbw7bx48x8xjgx9cmwq_180000gn/T/ipykernel_9746/3541696606.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  hf_embed   = HuggingFaceEmbeddings(model_name=embed_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index…\n",
      "Built & saved FAISS index.\n"
     ]
    }
   ],
   "source": [
    "embed_model = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "hf_embed   = HuggingFaceEmbeddings(model_name=embed_model)\n",
    "\n",
    "faiss_dir = Path(\"faiss_hindi_index\")\n",
    "if faiss_dir.exists():\n",
    "    vectordb = FAISS.load_local(str(faiss_dir), hf_embed)\n",
    "    print(\"Loaded existing FAISS index.\")\n",
    "else:\n",
    "    print(\"Building FAISS index…\")\n",
    "    vectordb = FAISS.from_documents(hindi_chunks, hf_embed)\n",
    "    vectordb.save_local(str(faiss_dir))\n",
    "    print(\"Built & saved FAISS index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f08a8ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bigscience/mt0-small on mps\n"
     ]
    }
   ],
   "source": [
    "model_id = \"bigscience/mt0-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "dtype = torch.float16 if DEVICE in (\"cuda\",\"mps\") else torch.float32\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, torch_dtype=dtype).to(DEVICE)\n",
    "\n",
    "hindi_pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    device=DEVICE_ID,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hindi_pipe)\n",
    "print(f\"Loaded {model_id} on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b4d215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi RetrievalQA chain ready\n"
     ]
    }
   ],
   "source": [
    "combine_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
    "qa_chain = RetrievalQA(\n",
    "    combine_documents_chain=combine_chain,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\":4}),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "print(\"Hindi RetrievalQA chain ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hindi_qa(question: str, verbose: bool=True):\n",
    "    prompt = f\"Answer in Hindi: {question}\"\n",
    "    out = qa_chain({\"query\": prompt})\n",
    "    ans = out[\"result\"]\n",
    "    srcs = out[\"source_documents\"]\n",
    "    if verbose:\n",
    "        print(\"\\n>>> प्रश्न:\\n\", question)\n",
    "        print(\"\\n>>> उत्तर:\\n\", ans)\n",
    "        print(\"\\n>>> स्रोत (chunks):\")\n",
    "        for d in srcs:\n",
    "            m = d.metadata\n",
    "            snip = d.page_content.replace(\"\\n\",\" \")[:200]\n",
    "            print(f\" • {m['source']} (chunk {m['chunk']}) → {snip}…\")\n",
    "    return ans, srcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "661f37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> प्रश्न:\n",
      " भारतीय संविधान का अनुच्छेद 370 क्या कहता है?\n",
      "\n",
      ">>> उत्तर:\n",
      " संविधान के अनुच्छेद 370 के खंड (1) के साथ पठित अनुच्छेद 370 के खंड (3) द्वारा प्रदत्त शक्तियों का प्रयोग करते हुए राष्ट्रपति ने जम्मू-कश्मीर के महाराजा की 5 मार्च, 1948 की उद्घोषणा के अधीन तत्समय पदस्थ मंत्रि-परिषद् की सलाह पर कार्य करने वाले जम्मू-कश्मीर के राजपाल के लिए निर्देशों को शामिल करता हुआ माना जाएगा ।\n",
      "\n",
      ">>> स्रोत (chunks):\n",
      " • Constitution_Hindi.txt (chunk 406) → जम्मू-कश्मीर राज्य को लागू होंगे ।\"। (परिशिष्ट 3 देखें) । 1. भारत का संविधान की खंड (3) द्वारा प्रदत्त शक्तियों का प्रयोग करते हुए राष्ट्रपति ने जम्मू-कश्मीर राज्य की संविधान सभा की सिफारिश पर यह घोषण…\n",
      " • Constitution_Hindi.txt (chunk 467) → 2. संविधान (सोलहवां संशोधन) अधिनियम, 1963 की धारा 5 द्वारा (5-10-1963 से) प्ररूप 3 के स्थान पर प्रतिस्थापित । (तीसरी अनुसूची) “मैं, अमुक, जो राज्य सभा (या लोक सभा) में स्थान भरने के लिए अभ्यर्थी के रू…\n",
      " • Constitution_Hindi.txt (chunk 468) → [मैं भारत की प्रभुता और अखंडता अक्षुण्ण रखूंगा,] तथा मैं सम्यक् प्रकार से और श्रद्धापूर्वक तथा अपनी पूरी योग्यता, ज्ञान और विवेक से अपने पद के कर्तव्यों का भय या पक्षपात, अनुराग या द्वेष के बिना पालन …\n",
      " • Constitution_Hindi.txt (chunk 602) → अनुच्छेद 367 में निम्नलिखित खंड जोड़ा जाएगा, अर्थात् :- “(4) संविधान, जहां तक यह जम्मू-कश्मीर के संबंध में लागू हैं, के प्रयोजनों के लिए- (क) इस संविधान या इसके उपबंधों के निर्देशों को, उक्त राज्य के …\n",
      "\n",
      ">>> प्रश्न:\n",
      " कृत्य या उपेक्षा तत्व क्या हैं?\n",
      "\n",
      ">>> उत्तर:\n",
      " अपवाद-यह उपबंध का विस्तार ऐसे मामले पर नहीं है, जिसमें संश्रय देना या छिपाना पकड़े जाने वाले व्यक्ति के पति या पत्नी द्वारा होने के आशय से संश्रय देना, या उनमें से किसी को दंड से प्रतिच्छादित करने के आशय से संश्रय देना, या उनमें से किसी को दंड से प्रतिच्छादित करने के आशय से संश्रय देना, या उनमें से किसी को दंड से प्रतिच्छादित करने के आशय से सं\n",
      "\n",
      ">>> स्रोत (chunks):\n",
      " • Constitution_Hindi.txt (chunk 52) → लेकर चलना सिक्ख धर्म के मानने का अंग समझा जाएगा । स्पष्टीकरण 2 - खंड (2) के उपखंड (ख) में हिंदुओं के प्रति निर्देश का यह अर्थ लगाया जाएगा कि उसके अंतर्गत सिक्ख, जैन या बौद्ध धर्म के मानने वाले व्यक्ति…\n",
      " • Constitution_Hindi.txt (chunk 550) → 3. संविधान (सातवां संशोधन) अधिनियम, 1956 की धारा 26 द्वारा (1-11-1956 से) प्रतिस्थापित । आठवीं अनुसूची [अनुच्छेद 344(1) और अनुच्छेद 351] भाषाएं 1. असमिया । 2. बंगला । 1[3. बोडो । 4. डोगरी ।] 2[5.] गुज…\n",
      " • IPC_hindi.txt (chunk 135) → 3 [ इस धारा में \"अपराध\" के अंतर्गत कोई भी ऐसा कार्य या लोप भी आता है, जिसका कोई व्यक्ति [भारत] से बाहर दोषी होना अभिकथित हो, जो यदि वह [भारत] में उसका दोषी होता, तो अपराध के रूप में दंडनीय होता और जिस…\n",
      " • Constitution_Hindi.txt (chunk 369) → वांछनीय हो वहां उसके शब्द-भंडार के लिए मुख्यतः संस्कृत से और गौणतः अन्य भाषाओं से शब्द ग्रहण करते हुए उसकी समृ‌द्धि सुनिश्चित करे । भाग 18 आपात उपबंध 352. आपात की उद्घोषणा (1) यदि राष्ट्रपति का यह समा…\n"
     ]
    }
   ],
   "source": [
    "_ = run_hindi_qa(\"भारतीय संविधान का अनुच्छेद 370 क्या कहता है?\")\n",
    "_ = run_hindi_qa(\"कृत्य या उपेक्षा तत्व क्या हैं?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
